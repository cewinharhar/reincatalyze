import torch 
import torch.nn as nn
import torch.optim as optim
import numpy as np
from transformers import AutoTokenizer, AutoModel, T5EncoderModel, T5Tokenizer
import re
import numpy as np
import requests
import json

from src.mainHelpers.prepare4APIRequest import prepare4APIRequest

class Policy(nn.Module):
    def __init__(self, device = "cuda:0", input_dim = 1024, hidden_dim = None, output_dim = None):
        super().__init__()
        self.device = device
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        """
        Is part of nn.Module and is required
        """
        embVec = self.embeddingRequest(torch.tensor(x))

        x = torch.relu(self.fc1(x))
        x = torch.softmax(self.fc2(x), dim=-1)
        return x

class ReinforcementLearningAgent:
    def __init__(self, device, input_dim, hidden_dim, output_dim, learning_rate, gamma):
        self.policy = Policy(device = device, input_dim = input_dim, hidden_dim = hidden_dim, output_dim=output_dim)
        self.optimizer = optim.Adam(self.policy.parameters(), lr=learning_rate)
        self.gamma = gamma
    
    def select_action(self, state):
        """
        state = Embedding vector
        """
        probs = self.policy(state)
        action = torch.multinomial(probs, 1)
        return action.item()
    
    
    def embeddingRequest(self, seq, embeddingUrl = "http://0.0.0.0/embedding"):
        #check if list, if not, make oen
        if not isinstance(seq, list):
            seq = [seq]

        payload = dict(inputSeq = seq)

        package = prepare4APIRequest(payload)

        try:
            response = requests.post(embeddingUrl, json=package).content.decode("utf-8")
            embedding = json.loads(response)    
            return embedding
        
        except requests.exceptions.RequestException as e:
            errMes = "Something went wrong\n" + str(e)
            print(errMes)
            raise Exception
    
    def update_policy(self, rewards, log_probs):
        discounted_rewards = []
        R = 0
        for r in rewards[::-1]:
            R = r + self.gamma * R
            discounted_rewards.insert(0, R)
        discounted_rewards = torch.tensor(discounted_rewards)
        discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9)
        policy_loss = []

        for log_prob, reward in zip(log_probs, discounted_rewards):
            policy_loss.append(-log_prob * reward)
        self.optimizer.zero_grad()
        policy_loss = torch.cat(policy_loss).sum()
        policy_loss.backward()
        self.optimizer.step()

def main():
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') 
    # Define the environment
    input_dim = 100 # Length of amino acid sequence
    output_dim = 20 # Number of amino acids
    LEARNING_RATE = 0.001
    DISCOUNT_FACTOR = 0.99

    # Define the agent
    model_name = 'Rostlab/prot_t5_xl_half_uniref50-enc'

    agent = ReinforcementLearningAgent(device = device,
                                       input_dim = input_dim, 
                                        hidden_dim = 64, 
                                        output_dim = output_dim,
                                        learning_rate = LEARNING_RATE, 
                                        gamma = DISCOUNT_FACTOR)
    

    
    # Run the episodes
    num_episodes = 10
    for episode in range(num_episodes):
        state = 'MSTETLRLQKARATEEGLAFETPGGLTRALRDGCFLLAVPPGFDTTPGVTLCRE' # Random initial amino acid sequence
        rewards = []
        log_probs = []
        for step in range(20):
            action = agent.select_action(state)
            new_state = list(state)
            new_state[action] = np.random.choice(list('ACDEFGHIKLMNPQRSTVWY')) # Randomly change amino acid at selected position
            new_state = ''.join(new_state)
            reward = np.random.rand(2)
            rewards.append(reward)
            log_probs.append(torch.log(agent.policy(new_state)))
            state = new_state
        agent.update_policy(rewards, log_probs)




#------------------------------------
import matplotlib.pyplot as plt

x = np.arange(len(embFin2.cpu()))

plt.bar(x = x , height =  embFin2.cpu())
plt.show()
#------------------------------------

b = agent.policy.embeddingRequest(seq = ["MAG"])
t = torch.tensor(b[0])
torch.relu(agent.policy(t))

agent.select_action("MAG")

agent.policy


